
# Proyecto de MinerÃ­a de Datos y ModelizaciÃ³n Predictiva

Este proyecto fue desarrollado como parte de la prÃ¡ctica de evaluaciÃ³n de la asignatura **MinerÃ­a de Datos y ModelizaciÃ³n Predictiva** del MÃ¡ster en Big Data, Data Science e Inteligencia Artificial (UCM).  
El objetivo fue construir modelos predictivos sobre datos reales de resultados electorales a nivel municipal en EspaÃ±a.

## Estructura del Proyecto

```
TareaMineriaGerson/
â”œâ”€â”€ data/
â”‚   â””â”€â”€ DatosEleccionesEspaÃ±a.xlsx
â”œâ”€â”€ informe/
â”‚   â”œâ”€â”€ TAREA GERSON CASTILLO MINERIA DE DATOS.pdf
â”‚   â”œâ”€â”€ curva_roc_punto_optimo.png
â”‚   â”œâ”€â”€ boxplot_auc_modelos.png
â”‚   â””â”€â”€ boxplot_r2_modelos.png
â”œâ”€â”€ src/
â”‚   â””â”€â”€ codigo_mineria.py
â”œâ”€â”€ librerias.txt
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore
```

## Objetivos

1. **Modelo de regresiÃ³n lineal** para predecir el porcentaje de abstenciÃ³n (`AbstentionPtge`) como variable continua.
2. **Modelo de regresiÃ³n logÃ­stica** para clasificar municipios en funciÃ³n de si tienen una abstenciÃ³n mayor a la mediana.

---

## MetodologÃ­a

### 1. AnÃ¡lisis Exploratorio y Limpieza

- ConversiÃ³n de cÃ³digos numÃ©ricos a categorÃ­as (`CodigoProvincia`).
- Reemplazo de valores errÃ³neos (`-99`, `9999`, etc.) y outliers.
- Tratamiento de valores perdidos y categorÃ­as con baja frecuencia.

### 2. SelecciÃ³n de Variables

- MÃ©todos clÃ¡sicos (`stepwise`, `forward`, `backward`) con criterios AIC y BIC.
- ValidaciÃ³n cruzada repetida para comparar rendimiento.
- SelecciÃ³n aleatoria de variables y evaluaciÃ³n de estabilidad.

### 3. Modelos Utilizados

#### ğŸ“ˆ RegresiÃ³n Lineal

Se utilizÃ³ la funciÃ³n de `statsmodels.OLS`. Se evaluÃ³ el RÂ² en train/test y se compararon varios modelos:

FÃ³rmula base del modelo:  
```python
y = Î²0 + Î²1X1 + Î²2X2 + ... + Î²nXn + Îµ
```

#### ğŸ“Š RegresiÃ³n LogÃ­stica

Se empleÃ³ `sklearn.linear_model.LogisticRegression`. Se predijo la probabilidad de que un municipio presente alta abstenciÃ³n (mayor a la mediana).

FÃ³rmula:  
```python
log(p / (1 - p)) = Î²0 + Î²1X1 + Î²2X2 + ... + Î²nXn
```

---

## Visualizaciones de Resultados

### 1. RÂ² en RegresiÃ³n Lineal

![R2 Lineal](informe/boxplot_r2_modelos.png)

### 2. AUC en RegresiÃ³n LogÃ­stica

![AUC LogÃ­stica](informe/boxplot_auc_modelos.png)

### 3. Curva ROC y Punto de Corte Ã“ptimo

Se calculÃ³ la distancia mÃ­nima al punto (0,1) para determinar el umbral Ã³ptimo de clasificaciÃ³n.

![Curva ROC](informe/curva_roc_punto_optimo.png)

---

## Resultados Clave

- **RegresiÃ³n lineal (Stepwise BIC)**: RÂ² test promedio â‰ˆ 0.74.
- **RegresiÃ³n logÃ­stica (Backward BIC)**: AUC test promedio â‰ˆ 0.86.
- El punto de corte Ã³ptimo en la curva ROC fue â‰ˆ 0.476.

---

## EjecuciÃ³n

1. Crear entorno virtual y activar:
```bash
conda create -n entornoMineria python=3.10
conda activate entornoMineria
```
2. Instalar librerÃ­as:
```bash
pip install -r librerias.txt
```
3. Ejecutar el cÃ³digo principal:
```bash
python src/codigo_mineria.py
```

---

## CrÃ©ditos

Desarrollado por **Gerson Castillo** como proyecto acadÃ©mico de la Universidad Complutense de Madrid.
